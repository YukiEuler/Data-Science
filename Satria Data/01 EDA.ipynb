{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kunjungan Prabowo ini untuk meresmikan dan men...</td>\n",
       "      <td>Sumber Daya Alam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT Anies dapat tepuk tangan meriah saat jadi R...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@CIqXqwGAT04tMtx4OCATxjoVq7vv/Y8HeYaIOgMFg8Y= ...</td>\n",
       "      <td>Demografi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @L3R8XFBw3WGbxRPSj0/0hHZTbqVGX7qtfwRg9zmhK7...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anies Baswedan Harap ASN termasuk TNI dan Polr...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>RT @l1DsGGe2xObT3t72dHwqlT58X7jvEYtEnauZIZSYwS...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Masyarakat yakin bahwa Prabowo-Gibran memiliki...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>imo both are irrational but yg satu jauh lebih...</td>\n",
       "      <td>Ekonomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>@cIIGSdjaPrmAQY1E4gWnLpIZSdyQn8ZMhjJzgOsxfRM= ...</td>\n",
       "      <td>Pertahanan dan Keamanan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Acara ini tidak hanya memasak, tetapi Calon Pr...</td>\n",
       "      <td>Sumber Daya Alam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     Kunjungan Prabowo ini untuk meresmikan dan men...   \n",
       "1     RT Anies dapat tepuk tangan meriah saat jadi R...   \n",
       "2     @CIqXqwGAT04tMtx4OCATxjoVq7vv/Y8HeYaIOgMFg8Y= ...   \n",
       "3     RT @L3R8XFBw3WGbxRPSj0/0hHZTbqVGX7qtfwRg9zmhK7...   \n",
       "4     Anies Baswedan Harap ASN termasuk TNI dan Polr...   \n",
       "...                                                 ...   \n",
       "4995  RT @l1DsGGe2xObT3t72dHwqlT58X7jvEYtEnauZIZSYwS...   \n",
       "4996  Masyarakat yakin bahwa Prabowo-Gibran memiliki...   \n",
       "4997  imo both are irrational but yg satu jauh lebih...   \n",
       "4998  @cIIGSdjaPrmAQY1E4gWnLpIZSdyQn8ZMhjJzgOsxfRM= ...   \n",
       "4999  Acara ini tidak hanya memasak, tetapi Calon Pr...   \n",
       "\n",
       "                        label  \n",
       "0            Sumber Daya Alam  \n",
       "1                     Politik  \n",
       "2                   Demografi  \n",
       "3                     Politik  \n",
       "4                     Politik  \n",
       "...                       ...  \n",
       "4995                  Politik  \n",
       "4996                  Politik  \n",
       "4997                  Ekonomi  \n",
       "4998  Pertahanan dan Keamanan  \n",
       "4999         Sumber Daya Alam  \n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Precompile regex patterns\n",
    "PATTERNS = {\n",
    "    'at': re.compile(r'@\\S+'),\n",
    "    'url': re.compile(r'https?\\S+'),\n",
    "    'bracket': re.compile(r'\\[.*?\\]'),\n",
    "    'non_ascii': re.compile(r'[^\\x00-\\x7F]+'),\n",
    "    'hashtag': re.compile(r'#\\S+'),\n",
    "    'rt': re.compile(r'\\brt\\b'),\n",
    "    'punctuation': re.compile(r'[^\\w\\s]')\n",
    "}\n",
    "\n",
    "# Default masks\n",
    "DEFAULT_MASKS = {\n",
    "    'at': 'PERSON_TAG_',\n",
    "    'url': 'URL_',\n",
    "    'bracket': 'RT_PERSON_',\n",
    "    'hashtag': 'HASHTAG_'\n",
    "}\n",
    "\n",
    "ADD_STOPWORDS = ['yg']\n",
    "\n",
    "def clean_text(text, \n",
    "               cln_punct=True, \n",
    "               mask_person=True, \n",
    "               mask_url=True, \n",
    "               mask_bracket=True, \n",
    "               mask_hashtag=True,\n",
    "               stopword = True,\n",
    "               lemma = True,):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Mask options\n",
    "    masks = {\n",
    "        'at': DEFAULT_MASKS['at'] if mask_person else '',\n",
    "        'url': DEFAULT_MASKS['url'] if mask_url else '',\n",
    "        'bracket': DEFAULT_MASKS['bracket'] if mask_bracket else '',\n",
    "        'hashtag': DEFAULT_MASKS['hashtag'] if mask_hashtag else ''\n",
    "    }\n",
    "\n",
    "    # Apply regex substitutions\n",
    "    text = PATTERNS['at'].sub(masks['at'], text)\n",
    "    text = PATTERNS['url'].sub(masks['url'], text)\n",
    "    text = PATTERNS['bracket'].sub(masks['bracket'], text)\n",
    "    text = PATTERNS['non_ascii'].sub('', text)\n",
    "    text = PATTERNS['hashtag'].sub(masks['hashtag'], text)\n",
    "    text = PATTERNS['rt'].sub('', text)\n",
    "    \n",
    "    if cln_punct:\n",
    "        text = PATTERNS['punctuation'].sub('', text)\n",
    "    if stopword:\n",
    "        stop_words = stopwords.words('indonesian')\n",
    "        stop_words = stop_words + ADD_STOPWORDS\n",
    "        text = ' '.join([word for word in word_tokenize(text) if word not in stop_words])\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "df['text_cleaned'] = df['text'].apply(lambda x: clean_text(x,lemma = False,mask_hashtag=False,mask_person=False,mask_url=False,mask_bracket=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
